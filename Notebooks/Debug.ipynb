{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import scipy\n",
    "import h5py\n",
    "import skimage\n",
    "from skimage import io,transform \n",
    "from collections import OrderedDict\n",
    "# old_code_dir = home + '/caffe_projects/TextureModel/code/'\n",
    "# sys.path.append(old_code_dir)\n",
    "# from DeepImageSynthesis import *\n",
    "home = '/gpfs01/bethge/home/lgatys/'\n",
    "project_dir = home + 'NeuralImageSynthesis/'\n",
    "photo_dir = home + '/neural-style/images/photos/'\n",
    "art_dir = home + '/neural-style/images/paintings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_torch_input(filename, layers, loss_functions, args):\n",
    "    f = h5py.File(filename,'w')\n",
    "    for l,layer in enumerate(layers):\n",
    "        layer_group = f.create_group(layer)\n",
    "        for lf,loss_function in enumerate(loss_functions[l]):\n",
    "            lf_group = layer_group.create_group(loss_function)\n",
    "            for arg in args[l][lf]:\n",
    "                dataset = lf_group.create_dataset(arg, data=args[l][lf][arg])\n",
    "    f.close()\n",
    "    \n",
    "def make_torch_init(filename, init):\n",
    "    f = h5py.File(filename,'w')\n",
    "    f.create_dataset('init', data=init)\n",
    "    f.close()\n",
    "\n",
    "def get_torch_output(filename):\n",
    "    f = h5py.File(filename,'r')\n",
    "    data = f['opt_result']\n",
    "    return data.value\n",
    "    f.close()\n",
    "\n",
    "def pass_layers(layers):\n",
    "    '''\n",
    "    Takes list of layers and returns comma separated list\n",
    "    '''\n",
    "    csl = str()\n",
    "    for l in layers:\n",
    "        csl = csl+l+','\n",
    "    return csl[:-1]\n",
    "\n",
    "def get_activations(images, caffe_model, layers='all', gpu=1):\n",
    "    '''\n",
    "    Function to get neural network activations in response to images from torch.\n",
    "    \n",
    "    :param images: array of images\n",
    "    :param caffe_model: file name of the network .caffemodel file\n",
    "    :param layers: network layers for which the activations should be computed\n",
    "    :return: network activations in response to images\n",
    "    '''\n",
    "    layers = pass_layers(layers)\n",
    "    tmp_dir = project_dir + 'Tmp/'\n",
    "    images_file_name = tmp_dir + 'images.hdf5'\n",
    "    output_file_name = tmp_dir + 'activations.hdf5'\n",
    "    f = h5py.File(images_file_name, 'w')\n",
    "    f.create_dataset('images', data=images)\n",
    "    f.close()\n",
    "    context = {\n",
    "    'caffe_model': caffe_model,\n",
    "    'images': images_file_name,\n",
    "    'layers': layers,\n",
    "    'gpu': gpu,\n",
    "    'backend': 'cudnn',\n",
    "    'output_file': output_file_name\n",
    "    }\n",
    "\n",
    "    template = ('#!/bin/bash\\n' +\n",
    "                '/usr/local/torch/install/bin/th ComputeActivations.lua ' + \n",
    "                '-caffe_model {caffe_model} ' +\n",
    "                '-images {images} ' + \n",
    "                '-layers {layers} ' + \n",
    "                '-gpu {gpu} ' + \n",
    "                '-backend {backend} ' +\n",
    "                '-output_file {output_file}')\n",
    "\n",
    "    script_name = project_dir + 'get_activations.sh'\n",
    "    with open(script_name, 'w') as script:\n",
    "        script.write(template.format(**context))\n",
    "    #execute script\n",
    "    !cd /gpfs01/bethge/home/lgatys/NeuralImageSynthesis/ && \\\n",
    "    ./get_activations.sh >/dev/null\n",
    "    \n",
    "    f = h5py.File(output_file_name,'r')\n",
    "    act = OrderedDict()\n",
    "    for key in f.keys():\n",
    "        act[key] = f[key].value.copy()\n",
    "    f.close()\n",
    "    return act\n",
    "\n",
    "def preprocess(image):\n",
    "    assert(image.max() <= 1.)\n",
    "    imagenet_mean = array([0.40760392,  0.45795686,  0.48501961])\n",
    "    image_torch = 255 * (image[:,:,::-1] - imagenet_mean).transpose(2,0,1)\n",
    "    return image_torch\n",
    "\n",
    "def deprocess(image_torch):\n",
    "    imagenet_mean = array([0.40760392,  0.45795686,  0.48501961])\n",
    "    image = (image_torch.transpose(1,2,0)/255. + imagenet_mean)[:,:,::-1]\n",
    "    image[image>1] = 1\n",
    "    image[image<0] = 0\n",
    "    return image\n",
    "\n",
    "def gram_matrix(activations):\n",
    "    n_fm = activations.shape[0]\n",
    "    F = activations.reshape(n_fm,-1)\n",
    "    G = F.dot(F.T) / F.size\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get images\n",
    "img_size = 450.\n",
    "conditions = ['content','style']\n",
    "img_names = OrderedDict()\n",
    "img_names['content'] = 'leon_cropped.jpg'\n",
    "img_names['style'] = 'vangogh_selfportrait.jpg'\n",
    "imgs = OrderedDict()\n",
    "imgs['content'] = imread(photo_dir + img_names['content'])\n",
    "imgs['content'] = transform.pyramid_reduce(imgs['content'], sqrt(float(imgs['content'][:,:,0].size) / img_size**2))\n",
    "imgs['style'] = imread(art_dir + img_names['style'])\n",
    "imgs['style'] = transform.pyramid_reduce(imgs['style'], sqrt(float(imgs['style'][:,:,0].size) / img_size**2))\n",
    "imgs_torch = OrderedDict()\n",
    "for cond in conditions:\n",
    "    imshow(imgs[cond]);show()\n",
    "    imgs_torch[cond] = preprocess(imgs[cond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get activations\n",
    "caffe_model = home + '/neural-style/models/VGG_ILSVRC_19_layers_conv.caffemodel'\n",
    "act = OrderedDict()\n",
    "for cond in conditions:\n",
    "    act[cond] = get_activations(imgs_torch[cond], caffe_model,\n",
    "                                           layers=['relu1_1','relu2_1','relu3_1','relu4_1','relu4_2','relu5_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "output_file_name = project_dir + 'Results/TorchOutput/output.hdf'\n",
    "layers = [\n",
    "    'relu1_1',\n",
    "    'relu2_1',\n",
    "    'relu3_1',\n",
    "    'relu4_1',\n",
    "    'relu4_2',\n",
    "    'relu5_1'\n",
    "]\n",
    "loss_functions = [\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['MSE'],\n",
    "    ['GramMSE']\n",
    "]\n",
    "args = [\n",
    "    [\n",
    "        {'target': gram_matrix(act['style']['relu1_1']),\n",
    "          'weight': array([1e3]), 'norm': array([0])}\n",
    "    ],\n",
    "        [\n",
    "        {'target': gram_matrix(act['style']['relu2_1']),\n",
    "          'weight': array([1e3]), 'norm': array([0])}\n",
    "    ],\n",
    "        [\n",
    "        {'target': gram_matrix(act['style']['relu3_1']),\n",
    "          'weight': array([1e3]), 'norm': array([0])}\n",
    "    ],\n",
    "        [\n",
    "        {'target': gram_matrix(act['style']['relu4_1']),\n",
    "          'weight': array([1e3]), 'norm': array([0])}\n",
    "    ],\n",
    "        [\n",
    "        {'target': act['content']['relu4_2'],\n",
    "          'weight': array([1]), 'norm': array([0])}\n",
    "    ],\n",
    "        [{'target': gram_matrix(act['style']['relu5_1']),\n",
    "          'weight': array([1e3]), 'norm': array([0])}\n",
    "        ]\n",
    "]\n",
    "make_torch_input(input_file_name, layers, loss_functions, args)\n",
    "make_torch_init(init_file_name, imgs_torch['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gpu = 1\n",
    "max_iter = 1000\n",
    "context = {\n",
    "    'caffe_model': caffe_model,\n",
    "    'input_file': input_file_name,\n",
    "    'init_file': init_file_name,\n",
    "    'gpu': gpu,\n",
    "    'max_iter': max_iter,\n",
    "    'backend': 'cudnn',\n",
    "    'print_iter': 50,\n",
    "    'save_iter': 0,\n",
    "    'layer_order': pass_layers(layers),\n",
    "    'output_file': output_file_name\n",
    "}\n",
    "\n",
    "template = (\n",
    "            '#!/bin/bash\\n' +\n",
    "            'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "            '-caffe_model {caffe_model} ' +\n",
    "            '-input_file {input_file} ' + \n",
    "            '-init_file {init_file} ' + \n",
    "            '-gpu {gpu} ' + \n",
    "            '-max_iter {max_iter} ' +\n",
    "            '-print_iter {print_iter} ' +\n",
    "            '-save_iter {save_iter} ' +\n",
    "            '-backend {backend} ' + \n",
    "            '-layer_order {layer_order} ' +\n",
    "            '-output_file {output_file}'\n",
    "           )\n",
    "\n",
    "script_name = project_dir + 'run_synthesis.sh'\n",
    "with open(script_name, 'w') as script:\n",
    "    script.write(template.format(**context))\n",
    "#execute script\n",
    "!cd /gpfs01/bethge/home/lgatys/NeuralImageSynthesis/ && \\\n",
    "./run_synthesis.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = deprocess(get_torch_output(output_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imsave(project_dir + 'Results/Images/test3.jpg', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
