{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import scipy\n",
    "import h5py\n",
    "import skimage\n",
    "from skimage import io,transform \n",
    "from collections import OrderedDict\n",
    "home = '/home/gatys/'\n",
    "project_dir = home + 'NeuralImageSynthesis/'\n",
    "photo_dir = project_dir + '/Images/Photos/'\n",
    "art_dir = project_dir + '/Images/Paintings/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Python helper functions - should move to python packge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_torch_input(filename, layers, loss_functions, args):\n",
    "    f = h5py.File(filename,'w')\n",
    "    for l,layer in enumerate(layers):\n",
    "        layer_group = f.create_group(layer)\n",
    "        for lf,loss_function in enumerate(loss_functions[l]):\n",
    "            lf_group = layer_group.create_group(loss_function)\n",
    "            for arg in args[l][lf]:\n",
    "                dataset = lf_group.create_dataset(arg, data=args[l][lf][arg])\n",
    "    f.close()\n",
    "    \n",
    "def make_torch_init(filename, init):\n",
    "    f = h5py.File(filename,'w')\n",
    "    f.create_dataset('init', data=init)\n",
    "    f.close()\n",
    "\n",
    "def get_torch_output(filename):\n",
    "    f = h5py.File(filename,'r')\n",
    "    data = f['opt_result']\n",
    "    return data.value\n",
    "    f.close()\n",
    "def get_torch_loss(filename):\n",
    "    f = h5py.File(filename,'r')\n",
    "    data = f['losses']\n",
    "    return data.value\n",
    "    f.close()\n",
    "\n",
    "def list2css(layers):\n",
    "    '''\n",
    "    Takes list of strings and returns comma separated string\n",
    "    '''\n",
    "    css = str()\n",
    "    for l in layers:\n",
    "        css = css+l+','\n",
    "    return css[:-1]\n",
    "\n",
    "def get_activations(images, caffe_model, layers='all', gpu=0):\n",
    "    '''\n",
    "    Function to get neural network activations in response to images from torch.\n",
    "    \n",
    "    :param images: array of images\n",
    "    :param caffe_model: file name of the network .caffemodel file\n",
    "    :param layers: network layers for which the activations should be computed\n",
    "    :return: network activations in response to images\n",
    "    '''\n",
    "    layers = list2css(layers)\n",
    "    tmp_dir = project_dir + 'Tmp/'\n",
    "    images_file_name = tmp_dir + 'images.hdf5'\n",
    "    output_file_name = tmp_dir + 'activations.hdf5'\n",
    "    f = h5py.File(images_file_name, 'w')\n",
    "    f.create_dataset('images', data=images)\n",
    "    f.close()\n",
    "    context = {\n",
    "    'caffe_model': caffe_model,\n",
    "    'images': images_file_name,\n",
    "    'layers': layers,\n",
    "    'gpu': gpu,\n",
    "    'backend': 'cudnn',\n",
    "    'output_file': output_file_name\n",
    "    }\n",
    "\n",
    "    template = ('#!/bin/bash\\n' +\n",
    "                '/usr/local/torch/install/bin/th ComputeActivations.lua ' + \n",
    "                '-caffe_model {caffe_model} ' +\n",
    "                '-images {images} ' + \n",
    "                '-layers {layers} ' + \n",
    "                '-gpu {gpu} ' + \n",
    "                '-backend {backend} ' +\n",
    "                '-output_file {output_file}')\n",
    "\n",
    "    script_name = project_dir + 'get_activations.sh'\n",
    "    with open(script_name, 'w') as script:\n",
    "        script.write(template.format(**context))\n",
    "    #execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "    !cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "    ./get_activations.sh >/dev/null\n",
    "    \n",
    "    f = h5py.File(output_file_name,'r')\n",
    "    act = OrderedDict()\n",
    "    for key in f.keys():\n",
    "        act[key] = f[key].value.copy()\n",
    "    f.close()\n",
    "    return act\n",
    "\n",
    "def preprocess(image):\n",
    "    assert(image.max() <= 1.)\n",
    "    imagenet_mean = array([0.40760392,  0.45795686,  0.48501961])\n",
    "    image_torch = 255 * (image[:,:,::-1] - imagenet_mean).transpose(2,0,1)\n",
    "    return image_torch\n",
    "\n",
    "def deprocess(image_torch):\n",
    "    imagenet_mean = array([0.40760392,  0.45795686,  0.48501961])\n",
    "    image = (image_torch.transpose(1,2,0)/255. + imagenet_mean)[:,:,::-1]\n",
    "    image[image>1] = 1\n",
    "    image[image<0] = 0\n",
    "    return image\n",
    "\n",
    "def gram_matrix(activations):\n",
    "    n_fm = activations.shape[0]\n",
    "    F = activations.reshape(n_fm,-1)\n",
    "    G = F.dot(F.T) / F[0,:].size\n",
    "    return G\n",
    "\n",
    "import itertools\n",
    "def flatten(l):\n",
    "    return list(itertools.chain.from_iterable(l))\n",
    "\n",
    "def set_model(name, project_dir):\n",
    "    if name == 'org_pad':\n",
    "        model = project_dir + 'Models/VGG_ILSVRC_19_layers_conv.caffemodel'\n",
    "    elif name == 'org_nopad':\n",
    "        model = project_dir + 'Models/VGG_ILSVRC_19_layers_conv_nopad.caffemodel'\n",
    "    elif name == 'norm_pad':\n",
    "        model = project_dir + 'Models/vgg_normalised.caffemodel'\n",
    "    elif name == 'norm_nopad':\n",
    "        model = project_dir + 'Models/vgg_normalised_nopad.caffemodel'\n",
    "    else:\n",
    "        assert False, 'unknown model name'\n",
    "    return model\n",
    "    \n",
    "def get_patch(image, x, y, h, w):\n",
    "    '''\n",
    "    Returns patch from image\n",
    "    x,y gives upper left corner\n",
    "    h,w gives height and width\n",
    "    '''\n",
    "    patch = image[y:y+h,x:x+w, :].copy()\n",
    "    return patch\n",
    "\n",
    "from skimage import transform\n",
    "import numpy as np\n",
    "def get_rotated_patch(image, x, y, h, w, angle):\n",
    "    '''\n",
    "    returns patch that is rotated by angle (radians) around patch center\n",
    "    '''\n",
    "    tf_rotate = transform.SimilarityTransform(rotation=angle)\n",
    "    tf_shift = transform.SimilarityTransform(translation=[-np.round(x+w/2), -np.round(y+h/2)])\n",
    "    tf_shift_inv = transform.SimilarityTransform(translation=[np.round(x+w/2), np.round(y+h/2)])\n",
    "    image_rotated = transform.warp(image, (tf_shift + (tf_rotate + tf_shift_inv)).inverse)\n",
    "    rotated_patch = get_patch(image_rotated, x, y, h, w)\n",
    "    return rotated_patch\n",
    "\n",
    "def match_color(target_img, source_img, mode='sym'):\n",
    "   '''\n",
    "   Matches the colour distribution of the target image to that of the source image\n",
    "   using a linear transform.\n",
    "   Images are expected to be of form (w,h,c).\n",
    "   Modes are chol, pca or sym for different choices of basis.\n",
    "   '''\n",
    "   mu_t = target_img.mean(0).mean(0)\n",
    "   t = target_img - mu_t\n",
    "   t = t.transpose(2,0,1).reshape(3,-1)\n",
    "   Ct = t.dot(t.T) / t.shape[1]\n",
    "   mu_s = source_img.mean(0).mean(0)\n",
    "   s = source_img - mu_s\n",
    "   s = s.transpose(2,0,1).reshape(3,-1)\n",
    "   Cs = s.dot(s.T) / s.shape[1]\n",
    "   if mode == 'chol':\n",
    "       chol_t = np.linalg.cholesky(Ct)\n",
    "       chol_s = np.linalg.cholesky(Cs)\n",
    "       ts = chol_s.dot(np.linalg.inv(chol_t)).dot(t)\n",
    "   if mode == 'pca':\n",
    "       eva_t, eve_t = np.linalg.eigh(Ct)\n",
    "       Qt = eve_t.dot(np.sqrt(np.diag(eva_t))).dot(eve_t.T)\n",
    "       eva_s, eve_s = np.linalg.eigh(Cs)\n",
    "       Qs = eve_s.dot(np.sqrt(np.diag(eva_s))).dot(eve_s.T)\n",
    "       ts = Qs.dot(np.linalg.inv(Qt)).dot(t)\n",
    "   if mode == 'sym':\n",
    "       eva_t, eve_t = np.linalg.eigh(Ct)\n",
    "       Qt = eve_t.dot(np.sqrt(np.diag(eva_t))).dot(eve_t.T)\n",
    "       Qt_Cs_Qt = Qt.dot(Cs).dot(Qt)\n",
    "       eva_QtCsQt, eve_QtCsQt = np.linalg.eigh(Qt_Cs_Qt)\n",
    "       QtCsQt = eve_QtCsQt.dot(np.sqrt(np.diag(eva_QtCsQt))).dot(eve_QtCsQt.T)\n",
    "       ts = np.linalg.inv(Qt).dot(QtCsQt).dot(np.linalg.inv(Qt)).dot(t)\n",
    "   matched_img = ts.reshape(*target_img.transpose(2,0,1).shape).transpose(1,2,0)\n",
    "   matched_img += mu_s\n",
    "   matched_img[matched_img>1] = 1\n",
    "   matched_img[matched_img<0] = 0\n",
    "   return matched_img\n",
    "\n",
    "def lum_transform(image):\n",
    "    img = image.transpose(2,0,1).reshape(3,-1)\n",
    "    lum = np.array([.299, .587, .114]).dot(img).squeeze()\n",
    "    img = tile(lum[None,:],(3,1)).reshape((3,image.shape[0],image.shape[1]))\n",
    "    return img.transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_style_c1(transfer_img, style_img, project_dir, model_name='org_pad', gpu=0, max_iter=500):\n",
    "    caffe_model = set_model(model_name, project_dir)\n",
    "    input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "    init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "    output_file_name = project_dir + 'Tmp/output.hdf5'\n",
    "    loss_file_name = project_dir + 'Tmp/loss.hdf5'\n",
    "    layers = ['relu1_1']\n",
    "    loss_functions = [['GramMSE']]\n",
    "    weights = [[array([1e3/64**2])]]\n",
    "    act = OrderedDict()\n",
    "    act['style'] = get_activations(style_img, caffe_model, layers=layers, gpu=gpu)\n",
    "    args = [\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[0]])[None,:],\n",
    "          'weights': weights[0][0]}\n",
    "    ],\n",
    "    ]\n",
    "    \n",
    "    make_torch_init(init_file_name, transfer_img)\n",
    "\n",
    "    context = {\n",
    "        'caffe_model': caffe_model,\n",
    "        'input_file': input_file_name,\n",
    "        'init_file': init_file_name,\n",
    "        'gpu': gpu,\n",
    "        'max_iter': max_iter,\n",
    "        'backend': 'cudnn',\n",
    "        'print_iter': 250,\n",
    "        'save_iter': 0,\n",
    "        'layer_order': list2css(layers),\n",
    "        'output_file': output_file_name,\n",
    "        'loss_file': loss_file_name\n",
    "    }\n",
    "    template = (\n",
    "                '#!/bin/bash\\n' +\n",
    "                'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "                '-caffe_model {caffe_model} ' +\n",
    "                '-input_file {input_file} ' + \n",
    "                '-init_file {init_file} ' + \n",
    "                '-gpu {gpu} ' + \n",
    "                '-max_iter {max_iter} ' +\n",
    "                '-print_iter {print_iter} ' +\n",
    "                '-save_iter {save_iter} ' +\n",
    "                '-backend {backend} ' + \n",
    "                '-layer_order {layer_order} ' +\n",
    "                '-output_file {output_file} ' +\n",
    "                '-loss_file {loss_file}'\n",
    "               )\n",
    "\n",
    "    script_name = project_dir + 'run_synthesis.sh'\n",
    "    with open(script_name, 'w') as script:\n",
    "        script.write(template.format(**context))\n",
    "    #execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "    !cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "    ./run_synthesis.sh\n",
    "    output = get_torch_output(output_file_name)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def transfer_style_c2(transfer_img, style_img, project_dir, model_name='org_pad', gpu=0, max_iter=500):\n",
    "    caffe_model = set_model(model_name, project_dir)\n",
    "    input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "    init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "    output_file_name = project_dir + 'Tmp/output.hdf5'\n",
    "    loss_file_name = project_dir + 'Tmp/loss.hdf5'\n",
    "    layers = ['relu1_1','relu2_1']\n",
    "    loss_functions = [['GramMSE']]*2\n",
    "    weights = [[array([1e3/64**2])], [array([1e3/128**2])]]\n",
    "    act = OrderedDict()\n",
    "    act['style'] = get_activations(style_img, caffe_model, layers=layers, gpu=gpu)\n",
    "    args = [\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[0]])[None,:],\n",
    "          'weights': weights[0][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[1]])[None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    ]\n",
    "    \n",
    "    make_torch_input(input_file_name, layers, loss_functions, args)\n",
    "    make_torch_init(init_file_name, transfer_img)\n",
    "    \n",
    "    context = {\n",
    "        'caffe_model': caffe_model,\n",
    "        'input_file': input_file_name,\n",
    "        'init_file': init_file_name,\n",
    "        'gpu': gpu,\n",
    "        'max_iter': max_iter,\n",
    "        'backend': 'cudnn',\n",
    "        'print_iter': 250,\n",
    "        'save_iter': 0,\n",
    "        'layer_order': list2css(layers),\n",
    "        'output_file': output_file_name,\n",
    "        'loss_file': loss_file_name\n",
    "    }\n",
    "    template = (\n",
    "                '#!/bin/bash\\n' +\n",
    "                'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "                '-caffe_model {caffe_model} ' +\n",
    "                '-input_file {input_file} ' + \n",
    "                '-init_file {init_file} ' + \n",
    "                '-gpu {gpu} ' + \n",
    "                '-max_iter {max_iter} ' +\n",
    "                '-print_iter {print_iter} ' +\n",
    "                '-save_iter {save_iter} ' +\n",
    "                '-backend {backend} ' + \n",
    "                '-layer_order {layer_order} ' +\n",
    "                '-output_file {output_file} ' +\n",
    "                '-loss_file {loss_file}'\n",
    "               )\n",
    "\n",
    "    script_name = project_dir + 'run_synthesis.sh'\n",
    "    with open(script_name, 'w') as script:\n",
    "        script.write(template.format(**context))\n",
    "    #execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "    !cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "    ./run_synthesis.sh\n",
    "    output = get_torch_output(output_file_name)\n",
    "    \n",
    "    return output\n",
    "def transfer_style_c3(transfer_img, style_img, project_dir, model_name='org_pad', gpu=0, max_iter=500):\n",
    "    caffe_model = set_model(model_name, project_dir)\n",
    "    input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "    init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "    output_file_name = project_dir + 'Tmp/output.hdf5'\n",
    "    loss_file_name = project_dir + 'Tmp/loss.hdf5'\n",
    "    layers = ['relu1_1','relu2_1','relu3_1']\n",
    "    loss_functions = [['GramMSE']]*3\n",
    "    weights = [[array([1e3/64**2])], [array([1e3/128**2])], [array([1e3/256**2])]]\n",
    "    act = OrderedDict()\n",
    "    act['style'] = get_activations(style_img, caffe_model, layers=layers, gpu=gpu)\n",
    "    args = [\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[0]])[None,:],\n",
    "          'weights': weights[0][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[1]])[None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[2]])[None,:],\n",
    "          'weights': weights[2][0]}\n",
    "    ],\n",
    "\n",
    "    ]\n",
    "    \n",
    "    make_torch_input(input_file_name, layers, loss_functions, args)\n",
    "    make_torch_init(init_file_name, transfer_img)\n",
    "    \n",
    "    context = {\n",
    "        'caffe_model': caffe_model,\n",
    "        'input_file': input_file_name,\n",
    "        'init_file': init_file_name,\n",
    "        'gpu': gpu,\n",
    "        'max_iter': max_iter,\n",
    "        'backend': 'cudnn',\n",
    "        'print_iter': 250,\n",
    "        'save_iter': 0,\n",
    "        'layer_order': list2css(layers),\n",
    "        'output_file': output_file_name,\n",
    "        'loss_file': loss_file_name\n",
    "    }\n",
    "    template = (\n",
    "                '#!/bin/bash\\n' +\n",
    "                'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "                '-caffe_model {caffe_model} ' +\n",
    "                '-input_file {input_file} ' + \n",
    "                '-init_file {init_file} ' + \n",
    "                '-gpu {gpu} ' + \n",
    "                '-max_iter {max_iter} ' +\n",
    "                '-print_iter {print_iter} ' +\n",
    "                '-save_iter {save_iter} ' +\n",
    "                '-backend {backend} ' + \n",
    "                '-layer_order {layer_order} ' +\n",
    "                '-output_file {output_file} ' +\n",
    "                '-loss_file {loss_file}'\n",
    "               )\n",
    "\n",
    "    script_name = project_dir + 'run_synthesis.sh'\n",
    "    with open(script_name, 'w') as script:\n",
    "        script.write(template.format(**context))\n",
    "    #execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "    !cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "    ./run_synthesis.sh\n",
    "    output = get_torch_output(output_file_name)\n",
    "    \n",
    "    return output\n",
    "def transfer_style_c4(transfer_img, style_img, project_dir, model_name='org_pad', gpu=0, max_iter=500):\n",
    "    caffe_model = set_model(model_name, project_dir)\n",
    "    input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "    init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "    output_file_name = project_dir + 'Tmp/output.hdf5'\n",
    "    loss_file_name = project_dir + 'Tmp/loss.hdf5'\n",
    "    layers = ['relu1_1','relu2_1','relu3_1', 'relu4_1']\n",
    "    loss_functions = [['GramMSE']]*4\n",
    "    weights = [[array([1e3/64**2])], [array([1e3/128**2])], [array([1e3/256**2])],[array([1e3/512**2])]]\n",
    "    act = OrderedDict()\n",
    "    act['style'] = get_activations(style_img, caffe_model, layers=layers, gpu=gpu)\n",
    "    args = [\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[0]])[None,:],\n",
    "          'weights': weights[0][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[1]])[None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[2]])[None,:],\n",
    "          'weights': weights[2][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': gram_matrix(act['style'][layers[3]])[None,:],\n",
    "          'weights': weights[3][0]}\n",
    "    ],\n",
    "    ]\n",
    "    \n",
    "    make_torch_input(input_file_name, layers, loss_functions, args)\n",
    "    make_torch_init(init_file_name, transfer_img)\n",
    "    \n",
    "    context = {\n",
    "        'caffe_model': caffe_model,\n",
    "        'input_file': input_file_name,\n",
    "        'init_file': init_file_name,\n",
    "        'gpu': gpu,\n",
    "        'max_iter': max_iter,\n",
    "        'backend': 'cudnn',\n",
    "        'print_iter': 250,\n",
    "        'save_iter': 0,\n",
    "        'layer_order': list2css(layers),\n",
    "        'output_file': output_file_name,\n",
    "        'loss_file': loss_file_name\n",
    "    }\n",
    "    template = (\n",
    "                '#!/bin/bash\\n' +\n",
    "                'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "                '-caffe_model {caffe_model} ' +\n",
    "                '-input_file {input_file} ' + \n",
    "                '-init_file {init_file} ' + \n",
    "                '-gpu {gpu} ' + \n",
    "                '-max_iter {max_iter} ' +\n",
    "                '-print_iter {print_iter} ' +\n",
    "                '-save_iter {save_iter} ' +\n",
    "                '-backend {backend} ' + \n",
    "                '-layer_order {layer_order} ' +\n",
    "                '-output_file {output_file} ' +\n",
    "                '-loss_file {loss_file}'\n",
    "               )\n",
    "\n",
    "    script_name = project_dir + 'run_synthesis.sh'\n",
    "    with open(script_name, 'w') as script:\n",
    "        script.write(template.format(**context))\n",
    "    #execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "    !cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "    ./run_synthesis.sh\n",
    "    output = get_torch_output(output_file_name)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style_image_names = ['turner_snowstorm.jpg','monet_iris.jpg','renoir_portrait_2.jpg','vangogh_starry2.jpg',\n",
    "                     'vangogh_starry_night.jpg', 'munch_schrei.jpg','signac_frau_terrasse.jpg','feininger_jesuiten.jpg',\n",
    "                     'picasso_seated_nude.jpg']\n",
    "for style_img_name in style_image_names:\n",
    "    imshow(imread(art_dir + style_img_name));show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get images and apply preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get images\n",
    "img_size = 450\n",
    "\n",
    "for st_sp in range(1,5):\n",
    "    \n",
    "img_names = OrderedDict()\n",
    "img_names['content'] = 'New_York_night.jpg'\n",
    "img_names['style_color'] = 'New_York_night.jpg'\n",
    "img_names['style_'+ str(st_sp)] = 'paint.jpg'\n",
    "img_names['style'] = 'picasso_seated_nude.jpg'\n",
    "\n",
    "imgs = OrderedDict()\n",
    "for key, img_name in img_names.iteritems():\n",
    "    try:\n",
    "        imgs[key] = imread(photo_dir + img_name)\n",
    "    except IOError:\n",
    "        imgs[key] = imread(art_dir + img_name)\n",
    "    imgs[key] = transform.pyramid_reduce(imgs[key], sqrt(float(imgs[key][:,:,0].size) / img_size**2))\n",
    "imgs_torch = OrderedDict()\n",
    "for key in imgs.keys():\n",
    "    imgs_torch[key] = preprocess(imgs[key])\n",
    "#transfer color onto later style images\n",
    "t = False\n",
    "for key in imgs.keys():\n",
    "    if t:\n",
    "        print(key, 'style_color')\n",
    "        imgs[key] = match_color(imgs[key], imgs['style_color'], mode='pca')\n",
    "        imgs_torch[key] = preprocess(imgs[key])\n",
    "    if key == 'style_color':\n",
    "        t = True        \n",
    "if t: #always transfer color on content image\n",
    "    print('content','style_color')\n",
    "    imgs['content'] = match_color(imgs['content'], imgs['style_color'], mode='pca')\n",
    "    imgs_torch['content'] = preprocess(imgs['content'])\n",
    "\n",
    "#transfer c1 style onto later style images\n",
    "t = False\n",
    "for key in imgs.keys():\n",
    "    if t:\n",
    "        print(key,'style_1')\n",
    "        imgs_torch[key] = transfer_style_c1(imgs_torch[key],imgs_torch['style_1'], project_dir)\n",
    "        imgs[key] = deprocess(imgs_torch[key])\n",
    "    if key == 'style_1':\n",
    "        t = True\n",
    "\n",
    "#transfer c2 style onto later style images\n",
    "t = False\n",
    "for key in imgs.keys():\n",
    "    if t:\n",
    "        print(key,'style_2')\n",
    "        imgs_torch[key] = transfer_style_c2(imgs_torch[key],imgs_torch['style_2'], project_dir, gpu=gpu)\n",
    "        imgs[key] = deprocess(imgs_torch[key])\n",
    "    if key == 'style_2':\n",
    "        t = True\n",
    "\n",
    "#transfer c3 style onto later style images\n",
    "t = False\n",
    "for key in imgs.keys():\n",
    "    if t:\n",
    "        print(key,'style_3')\n",
    "        imgs_torch[key] = transfer_style_c3(imgs_torch[key],imgs_torch['style_3'], project_dir, gpu=gpu)\n",
    "        imgs[key] = deprocess(imgs_torch[key])\n",
    "    if key == 'style_3':\n",
    "        t = True\n",
    "\n",
    "#transfer c4 style onto later style images\n",
    "t = False\n",
    "for key in imgs.keys():\n",
    "    if t:\n",
    "        print(key,'style_4')\n",
    "        imgs_torch[key] = transfer_style_c4(imgs_torch[key],imgs_torch['style_4'], project_dir, gpu=gpu)\n",
    "        imgs[key] = deprocess(imgs_torch[key])\n",
    "    if key == 'style_4':\n",
    "        t = True\n",
    "\n",
    "for key in imgs.keys():\n",
    "    imshow(imgs[key], interpolation='nearest');show()\n",
    "    \n",
    "#get activations for all images\n",
    "model_name = 'org_pad'\n",
    "caffe_model = set_model(model_name, project_dir)\n",
    "gpu = 0\n",
    "input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "output_file_name = project_dir + 'Tmp/output.hdf5'\n",
    "loss_file_name = project_dir + 'Tmp/loss.hdf5'\n",
    "layers = [\n",
    "    'relu1_1',\n",
    "    'relu2_1',\n",
    "    'relu3_1',\n",
    "    'relu4_1',\n",
    "    'relu4_2',\n",
    "    'relu5_1'\n",
    "]\n",
    "loss_functions = [\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['MSE'],\n",
    "    ['GramMSE']\n",
    "]\n",
    "sw = 1e3\n",
    "cw = 1\n",
    "weights = [\n",
    "    [array([sw/64**2])],\n",
    "    [array([sw/128**2])],\n",
    "    [array([sw/256**2])],\n",
    "    [array([sw/512**2])],\n",
    "    [array([cw])],    \n",
    "    [array([sw/512**2])],\n",
    "]\n",
    "#compute activations\n",
    "act = OrderedDict()\n",
    "act['content'] = get_activations(imgs_torch['content'], caffe_model, layers=layers,gpu=gpu)\n",
    "act['style'] = get_activations(imgs_torch['style'], caffe_model, layers=layers,gpu=gpu)\n",
    "\n",
    "#set arguments and run synthesis\n",
    "sc = 1\n",
    "args = [\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[0]])[None,:],\n",
    "          'weights': weights[0][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[1]])[None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[2]])[None,:],\n",
    "          'weights': weights[2][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[3]])[None,:],\n",
    "          'weights': weights[3][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': act['content'][layers[4]][None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[5]])[None,:],\n",
    "          'weights': weights[5][0]}\n",
    "    ],\n",
    "]\n",
    "make_torch_input(input_file_name, layers, loss_functions, args)\n",
    "make_torch_init(init_file_name, imgs_torch['content'])\n",
    "\n",
    "#run image synthesis\n",
    "max_iter = 500\n",
    "context = {\n",
    "    'caffe_model': caffe_model,\n",
    "    'input_file': input_file_name,\n",
    "    'init_file': init_file_name,\n",
    "    'gpu': gpu,\n",
    "    'max_iter': max_iter,\n",
    "    'backend': 'cudnn',\n",
    "    'print_iter': 50,\n",
    "    'save_iter': 0,\n",
    "    'layer_order': list2css(layers),\n",
    "    'output_file': output_file_name,\n",
    "    'loss_file': loss_file_name\n",
    "}\n",
    "\n",
    "template = (\n",
    "            '#!/bin/bash\\n' +\n",
    "            'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "            '-caffe_model {caffe_model} ' +\n",
    "            '-input_file {input_file} ' + \n",
    "            '-init_file {init_file} ' + \n",
    "            '-gpu {gpu} ' + \n",
    "            '-max_iter {max_iter} ' +\n",
    "            '-print_iter {print_iter} ' +\n",
    "            '-save_iter {save_iter} ' +\n",
    "            '-backend {backend} ' + \n",
    "            '-layer_order {layer_order} ' +\n",
    "            '-output_file {output_file} ' +\n",
    "            '-loss_file {loss_file}'\n",
    "           )\n",
    "\n",
    "script_name = project_dir + 'run_synthesis.sh'\n",
    "with open(script_name, 'w') as script:\n",
    "    script.write(template.format(**context))\n",
    "#execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "!cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "./run_synthesis.sh\n",
    "output = deprocess(get_torch_output(output_file_name))\n",
    "imshow(output,interpolation='nearest');show()\n",
    "\n",
    "#save image\n",
    "lf = list2css(map(str,loss_functions))\n",
    "lf = str.replace(lf,'[','_')\n",
    "lf = str.replace(lf,']','_')\n",
    "w = list2css([format(str([weight[i][0] for i in range(len(weight))]),'.4') for weight in weights])\n",
    "w = str.replace(w,'[','_')\n",
    "w = str.replace(w,']','_')\n",
    "result_image_name = (\n",
    "'cimg_cm_' + img_names['content'] + '_' +\n",
    "'scimg_' + img_names['style_color'] +\n",
    "'_s'+str(st_sp)+'img_' + img_names['style_'+str(st_sp)] +\n",
    "'_simg_' + img_names['style'] +\n",
    "'_sz_' + str(img_size) + \n",
    "'_model_' + model_name + \n",
    "# '_layers_' + list2css(layers) + \n",
    "# '_lf_' + lf +\n",
    "# '_weights_' + w + \n",
    "# '_sc_' + str(sc) + \n",
    "'.jpg'\n",
    ")\n",
    "imsave(project_dir + 'Results/Images/' + result_image_name, output)\n",
    "\n",
    "#save loss file\n",
    "losses = get_torch_loss(loss_file_name)\n",
    "#     losses /= wei #divide by scaling factor\n",
    "result_loss_name = result_image_name[:-4] + '_losses.npy'\n",
    "save(project_dir + 'Results/Losses/' + result_loss_name, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make it highres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get images\n",
    "img_size = 1000\n",
    "img_hr_names = OrderedDict()\n",
    "img_hr_names['content'] = 'New_York_night.jpg'\n",
    "img_hr_names['style_color'] = 'New_York_night.jpg'\n",
    "img_hr_names['style_2'] = 'paint.jpg'\n",
    "\n",
    "imgs_hr = OrderedDict()\n",
    "for key, img_name in img_hr_names.iteritems():\n",
    "    try:\n",
    "        imgs_hr[key] = imread(photo_dir + img_name)\n",
    "    except IOError:\n",
    "        imgs_hr[key] = imread(art_dir + img_name)\n",
    "    scale_factor = sqrt(float(imgs_hr[key][:,:,0].size) / img_size**2)\n",
    "    if scale_factor > 1:\n",
    "        imgs_hr[key] = transform.pyramid_reduce(imgs_hr[key], scale_factor)\n",
    "    else:\n",
    "        imgs_hr[key] =  imgs_hr[key] / 255.\n",
    "    \n",
    "#upsample the preprocessed style image\n",
    "scale_factor = sqrt(float(imgs['style'][:,:,0].size) / img_size**2)\n",
    "imgs_hr['style'] = transform.pyramid_expand(imgs['style'], 1./scale_factor)\n",
    "\n",
    "imgs_hr_torch = OrderedDict()\n",
    "for key in imgs_hr.keys():\n",
    "    imgs_hr_torch[key] = preprocess(imgs_hr[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transfer color onto later style images\n",
    "t = False\n",
    "for key in imgs_hr.keys():\n",
    "    if t:\n",
    "        print(key, 'style_color')\n",
    "        imgs_hr[key] = match_color(imgs_hr[key], imgs_hr['style_color'], mode='pca')\n",
    "        imgs_hr_torch[key] = preprocess(imgs_hr[key])\n",
    "    if key == 'style_color':\n",
    "        t = True        \n",
    "if t: #always transfer color on content image\n",
    "    print('content','style_color')\n",
    "    imgs_hr['content'] = match_color(imgs_hr['content'], imgs_hr['style_color'], mode='pca')\n",
    "    imgs_hr_torch['content'] = preprocess(imgs_hr['content'])\n",
    "\n",
    "#transfer c1 style onto later style images\n",
    "t = False\n",
    "for key in imgs_hr.keys():\n",
    "    if t:\n",
    "        print(key,'style_1')\n",
    "        imgs_hr_torch[key] = transfer_style_c1(imgs_hr_torch[key],imgs_hr_torch['style_1'], project_dir, max_iter=200)\n",
    "        imgs_hr[key] = deprocess(imgs_hr_torch[key])\n",
    "    if key == 'style_1':\n",
    "        t = True\n",
    "\n",
    "#transfer c2 style onto later style images\n",
    "t = False\n",
    "for key in imgs_hr.keys():\n",
    "    if t:\n",
    "        print(key,'style_2')\n",
    "        imgs_hr_torch[key] = transfer_style_c2(imgs_hr_torch[key],imgs_hr_torch['style_2'], project_dir)\n",
    "        imgs_hr[key] = deprocess(imgs_hr_torch[key])\n",
    "    if key == 'style_2':\n",
    "        t = True\n",
    "\n",
    "#transfer c3 style onto later style images\n",
    "t = False\n",
    "for key in imgs_hr.keys():\n",
    "    if t:\n",
    "        print(key,'style_3')\n",
    "        imgs_hr_torch[key] = transfer_style_c3(imgs_hr_torch[key],imgs_hr_torch['style_3'], project_dir)\n",
    "        imgs_hr[key] = deprocess(imgs_hr_torch[key])\n",
    "    if key == 'style_3':\n",
    "        t = True\n",
    "\n",
    "#transfer c4 style onto later style images\n",
    "t = False\n",
    "for key in imgs_hr.keys():\n",
    "    if t:\n",
    "        print(key,'style_4')\n",
    "        imgs_hr_torch[key] = transfer_style_c4(imgs_hr_torch[key],imgs_hr_torch['style_4'], project_dir)\n",
    "        imgs_hr[key] = deprocess(imgs_hr_torch[key])\n",
    "    if key == 'style_4':\n",
    "        t = True\n",
    "\n",
    "for key in imgs_hr.keys():\n",
    "    imshow(imgs_hr[key], interpolation='nearest');show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get activations for all images\n",
    "model_name = 'org_pad'\n",
    "caffe_model = set_model(model_name, project_dir)\n",
    "gpu = 0\n",
    "input_file_name = project_dir + 'Tmp/input.hdf5'\n",
    "init_file_name = project_dir + 'Tmp/init.hdf5'\n",
    "output_file_name = project_dir + 'Tmp/output.hdf5'\n",
    "loss_file_name = project_dir + 'Tmp/loss.hdf5'\n",
    "layers = [\n",
    "    'relu1_1',\n",
    "    'relu2_1',\n",
    "    'relu3_1',\n",
    "    'relu4_1',\n",
    "    'relu4_2',\n",
    "    'relu5_1'\n",
    "]\n",
    "loss_functions = [\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['GramMSE'],\n",
    "    ['MSE'],\n",
    "    ['GramMSE']\n",
    "]\n",
    "sw = 1e3\n",
    "cw = 1\n",
    "weights = [\n",
    "    [array([sw/64**2])],\n",
    "    [array([sw/128**2])],\n",
    "    [array([sw/256**2])],\n",
    "    [array([sw/512**2])],\n",
    "    [array([cw])],    \n",
    "    [array([sw/512**2])],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compute activations\n",
    "act = OrderedDict()\n",
    "act['content'] = get_activations(imgs_hr_torch['content'], caffe_model, layers=layers,gpu=gpu)\n",
    "act['style'] = get_activations(imgs_hr_torch['style'], caffe_model, layers=layers,gpu=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set arguments and run synthesis\n",
    "sc = 1\n",
    "args = [\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[0]])[None,:],\n",
    "          'weights': weights[0][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[1]])[None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[2]])[None,:],\n",
    "          'weights': weights[2][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[3]])[None,:],\n",
    "          'weights': weights[3][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': act['content'][layers[4]][None,:],\n",
    "          'weights': weights[1][0]}\n",
    "    ],\n",
    "    [\n",
    "        {'targets': sc * gram_matrix(act['style'][layers[5]])[None,:],\n",
    "          'weights': weights[5][0]}\n",
    "    ],\n",
    "]\n",
    "make_torch_input(input_file_name, layers, loss_functions, args)\n",
    "hr_init = preprocess(scipy.misc.imresize(output, imgs_hr['content'].shape)/255.)\n",
    "make_torch_init(init_file_name, hr_init)\n",
    "\n",
    "#run image synthesis\n",
    "max_iter = 200\n",
    "context = {\n",
    "    'caffe_model': caffe_model,\n",
    "    'input_file': input_file_name,\n",
    "    'init_file': init_file_name,\n",
    "    'gpu': gpu,\n",
    "    'max_iter': max_iter,\n",
    "    'backend': 'cudnn',\n",
    "    'print_iter': 50,\n",
    "    'save_iter': 0,\n",
    "    'layer_order': list2css(layers),\n",
    "    'output_file': output_file_name,\n",
    "    'loss_file': loss_file_name\n",
    "}\n",
    "\n",
    "template = (\n",
    "            '#!/bin/bash\\n' +\n",
    "            'time /usr/local/torch/install/bin/th ImageSynthesis.lua ' + \n",
    "            '-caffe_model {caffe_model} ' +\n",
    "            '-input_file {input_file} ' + \n",
    "            '-init_file {init_file} ' + \n",
    "            '-gpu {gpu} ' + \n",
    "            '-max_iter {max_iter} ' +\n",
    "            '-print_iter {print_iter} ' +\n",
    "            '-save_iter {save_iter} ' +\n",
    "            '-backend {backend} ' + \n",
    "            '-layer_order {layer_order} ' +\n",
    "            '-output_file {output_file} ' +\n",
    "            '-loss_file {loss_file}'\n",
    "           )\n",
    "\n",
    "script_name = project_dir + 'run_synthesis.sh'\n",
    "with open(script_name, 'w') as script:\n",
    "    script.write(template.format(**context))\n",
    "#execute script PATH NEEDS TO BE CHANGED ON NEW MACHINE\n",
    "!cd /home/gatys/NeuralImageSynthesis/ && \\\n",
    "./run_synthesis.sh\n",
    "output = deprocess(get_torch_output(output_file_name))\n",
    "imshow(output,interpolation='nearest');show()\n",
    "\n",
    "#save image\n",
    "lf = list2css(map(str,loss_functions))\n",
    "lf = str.replace(lf,'[','_')\n",
    "lf = str.replace(lf,']','_')\n",
    "w = list2css([format(str([weight[i][0] for i in range(len(weight))]),'.4') for weight in weights])\n",
    "w = str.replace(w,'[','_')\n",
    "w = str.replace(w,']','_')\n",
    "result_image_name = (\n",
    "'cimg_cm_' + img_names['content'] + '_' +\n",
    "'scimg_' + img_names['style_color'] +\n",
    "# '_s1img_' + img_names['style_1'] +\n",
    "'_s2img_' + img_names['style_2'] +\n",
    "# '_s3img_' + img_names['style_3'] +\n",
    "# '_s4img_' + img_names['style_4'] +\n",
    "'_simg_' + img_names['style'] +\n",
    "'_sz_' + str(img_size) + \n",
    "'_model_' + model_name + \n",
    "# '_layers_' + list2css(layers) + \n",
    "# '_lf_' + lf +\n",
    "# '_weights_' + w + \n",
    "# '_sc_' + str(sc) + \n",
    "'_hr.jpg')\n",
    "imsave(project_dir + 'Results/Images/' + result_image_name, output)\n",
    "\n",
    "#save loss file\n",
    "losses = get_torch_loss(loss_file_name)\n",
    "#     losses /= wei #divide by scaling factor\n",
    "result_loss_name = result_image_name[:-4] + '_losses.npy'\n",
    "save(project_dir + 'Results/Losses/' + result_loss_name, losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
